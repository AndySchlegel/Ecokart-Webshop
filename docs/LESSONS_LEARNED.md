# ğŸ“š Lessons Learned - Ecokart E-Commerce Projekt

**Von:** Andy Schlegel
**Projekt:** Ecokart - Serverless E-Commerce Platform
**Zeitraum:** November 2025
**Status:** Von Demo zu Production-Ready

---

## ğŸ¯ Projekt-Ãœberblick

Dieses Dokument beschreibt die wichtigsten **Learnings, Herausforderungen und LÃ¶sungen** wÃ¤hrend der Entwicklung von Ecokart - ein vollstÃ¤ndiger E-Commerce Shop auf AWS Serverless Infrastructure.

**Ziel:** Von einem einfachen Tutorial-Projekt zu einem **professionellen, production-ready Setup** mit Multi-Environment Support, CI/CD Pipeline und Best Practices.

---

## ğŸ† Haupterfolge

### âœ… Was ich erreicht habe:

1. **Multi-Environment Infrastructure Setup**
   - Development, Staging, Production Environments
   - Environment-spezifische Terraform Configs
   - Kostenoptimierung durch unterschiedliche Ressourcen-GrÃ¶ÃŸen

2. **Vollautomatische CI/CD Pipeline**
   - GitHub Actions mit OIDC (ohne AWS Keys!)
   - Branch-basiertes automatisches Deployment
   - Automated Destroy Workflow mit Sicherheits-Checks

3. **Funktionierender E-Commerce Shop**
   - 31 Produkte im Katalog
   - User-Registrierung & Login
   - Warenkorb-System
   - Bestellungs-Management
   - Admin-Panel fÃ¼r Produkt-Verwaltung

4. **Infrastructure as Code**
   - 100% Terraform
   - Modularisierte Terraform-Module
   - Wiederverwendbare Komponenten

---

## ğŸ’¡ Wichtigste Learnings

### 1. Git Branching-Strategien sind essentiell

**Das Problem:**
Anfangs habe ich nur auf `main` gepusht - jede Ã„nderung ging direkt live. Riskant und unprofessionell!

**Die LÃ¶sung:**
```
develop â†’ staging â†’ main
   â†“         â†“        â†“
  Test    Pre-Prod  Production
```

**Was ich gelernt habe:**
- **Niemals direkt in main pushen!**
- Develop zum Experimentieren nutzen
- Staging fÃ¼r finale Tests vor Production
- Pull Requests fÃ¼r Code Review nutzen

**Anwendung im echten Job:**
- Standard in allen professionellen Teams
- Verhindert Production-AusfÃ¤lle
- ErmÃ¶glicht parallele Feature-Entwicklung

---

### 2. Infrastructure as Code (Terraform) ist mÃ¤chtig aber trickreich

**Herausforderung: Terraform State Management**

**Das Problem:**
```
Error: Resource already exists: ecokart-development-api
```

Terraform wollte Ressourcen erstellen, die schon existierten. Warum? **Der Terraform State** (die "GedÃ¤chtnis"-Datei) war leer oder verloren gegangen.

**Die LÃ¶sung:**
1. Alte Ressourcen manuell lÃ¶schen (Destroy Workflow)
2. Neu erstellen mit frischem State
3. **Lesson:** SpÃ¤ter Remote State (S3) nutzen!

**Was ich gelernt habe:**
- Terraform State ist KRITISCH
- Lokaler State ist fragil
- Remote State (S3 + DynamoDB Lock) ist Best Practice
- Immer mit `terraform plan` checken vor `apply`

---

### 3. .gitignore kann in mehreren Verzeichnissen sein!

**Das Problem:**
Meine Environment-Configs (`development.tfvars`, `staging.tfvars`, `production.tfvars`) wurden nicht committed!

**Die Ursache:**
```
terraform/.gitignore:
*.tfvars   # â† Das blockierte ALLE .tfvars Dateien!
```

**Die LÃ¶sung:**
```
terraform/.gitignore:
*.tfvars
!terraform.tfvars.example
!environments/*.tfvars   # â† Ausnahme hinzugefÃ¼gt!
```

**Was ich gelernt habe:**
- `.gitignore` kann in jedem Unterverzeichnis sein
- Immer ALLE `.gitignore` Dateien checken
- Ausnahmen mit `!` definieren
- **WHY:** `.tfvars` enthÃ¤lt normalerweise Secrets â†’ sollte nicht committed werden. ABER unsere Environment-Configs haben keine Secrets!

---

### 4. AWS braucht Zeit zum AufrÃ¤umen von Ressourcen

**Das Problem:**
Nach `terraform destroy` war alles weg (laut Workflow), aber beim Re-Deploy: **"Lambda already exists"**!

**Die Ursache:**
- Terraform Destroy war fertig
- AWS brauchte noch 2-3 Minuten zum tatsÃ¤chlichen LÃ¶schen
- Ich hab zu schnell neu deployed

**Die LÃ¶sung:**
```
1. Destroy Workflow laufen lassen
2. â° 3-5 Minuten WARTEN
3. Erst dann neu deployen
```

**Was ich gelernt habe:**
- AWS Operationen sind asynchron
- "Deleted" â‰  "Wirklich weg"
- Immer Buffer-Zeit einplanen
- Bei Production: Monitoring fÃ¼r Failed Deletes

---

### 5. Two-Layer Authentication Design

**Die Architektur:**
```
Layer 1: Basic Auth (Amplify Level)
  â†“
Layer 2: App Login (Backend JWT)
```

**Warum zwei Layers?**

**Basic Auth (Layer 1):**
- Schneller Schutz vor zufÃ¤lligen Besuchern
- Verhindert Bots/Crawler
- Gut fÃ¼r Development/Staging
- **Nachteil:** Nicht production-ready (zu simpel)

**JWT Auth (Layer 2):**
- Echte User-Authentifizierung
- Session-Management
- Role-based Access (User vs. Admin)
- **SpÃ¤ter:** Wird durch AWS Cognito ersetzt

**Was ich gelernt habe:**
- Security in Layers denken
- Basic Auth als temporÃ¤re LÃ¶sung OK
- FÃ¼r Production: Cognito oder OAuth nÃ¶tig

---

### 6. Cost Optimization durch Environment-Sizing

**Die Strategie:**

| Environment | Lambda RAM | DynamoDB Mode | Kosten/Monat |
|-------------|------------|---------------|--------------|
| Development | 256 MB | PAY_PER_REQUEST | ~25 EUR |
| Staging | 512 MB | PROVISIONED (low) | ~50 EUR |
| Production | 1024 MB | PROVISIONED (high) | ~120 EUR |

**Was ich gelernt habe:**
- Development muss NICHT wie Production aussehen
- Development: Klein & gÃ¼nstig (zum Testen)
- Staging: Production-Ã¤hnlich (fÃ¼r finale Tests)
- Production: Volle Power (fÃ¼r echte Kunden)
- **Saving:** Statt 3x 120 EUR = 360 EUR â†’ nur 195 EUR/Monat!

**Mein Ansatz:**
- Development nur hochfahren wenn ich aktiv entwickle
- Nach Session: Destroy â†’ spart ~75% der Kosten!
- Sandbox-Budget (15$/Monat) reicht locker!

---

### 7. GitHub Actions OIDC ist besser als Access Keys

**Vorher (unsicher):**
```yaml
env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_KEY }}
```

**Jetzt (sicher):**
```yaml
- uses: aws-actions/configure-aws-credentials@v4
  with:
    role-to-assume: ${{ secrets.AWS_ROLE_ARN }}  # Nur Role ARN!
```

**Vorteile:**
- âœ… Keine langlebigen Credentials in GitHub
- âœ… Automatische Token-Rotation
- âœ… Granulare Permissions (nur was gebraucht wird)
- âœ… Audit-Trail in AWS CloudTrail

**Was ich gelernt habe:**
- OIDC ist moderner Standard
- AWS Keys sind Legacy
- Security-Best-Practice aus echten Jobs

---

### 8. Debugging: Manuell in AWS Console checken!

**Die Situation:**
Workflow sagt "Lambda deleted", aber Deploy sagt "Lambda exists"!

**Was ich gemacht habe:**
1. âœ… AWS Lambda Console geÃ¶ffnet
2. âœ… Manuell gecheckt: Lambda war noch da!
3. âœ… Manuell gelÃ¶scht
4. âœ… Problem gelÃ¶st

**Was ich gelernt habe:**
- **Nicht blind Workflows vertrauen!**
- Immer manuell verifizieren bei Problemen
- AWS Console kennen ist wichtig
- Automation + Manual Check = Best Practice

---

## ğŸš§ GrÃ¶ÃŸte Herausforderungen

### Challenge #1: Amplify Webhook Permissions (8 Iterationen!)

**Das Problem:**
```
AccessDeniedException: amplify:CreateWebhook on resource:
arn:aws:amplify:eu-north-1:xxx:apps/xxx/branches/main
```

**Die LÃ¶sung (nach 8 Versuchen!):**
IAM Policy braucht **2 separate Statements:**
```hcl
# Statement 1: CreateWebhook auf APP-Ressource
Resource = "arn:aws:amplify:*:*:apps/*"
Actions = ["amplify:CreateWebhook", "amplify:DeleteWebhook"]

# Statement 2: GetWebhook auf WEBHOOK-Ressource
Resource = "arn:aws:amplify:*:*:apps/*/webhooks/*"
Actions = ["amplify:GetWebhook", "amplify:ListWebhooks"]
```

**Was ich gelernt habe:**
- AWS IAM Permissions sind SEHR granular
- Unterschiedliche Actions operieren auf unterschiedlichen Ressourcen
- AWS Dokumentation ist manchmal unclear
- Trial & Error ist manchmal nÃ¶tig (aber dokumentieren!)

---

### Challenge #2: Table-Namen Mismatch im Cleanup-Script

**Das Problem:**
Cleanup-Script suchte `ecokart-development-products` (mit -development Suffix), aber echte Tables heiÃŸen `ecokart-products` (ohne Suffix)!

**Die LÃ¶sung:**
```bash
# Vorher (FALSCH)
TABLES=("ecokart-development-products")

# Nachher (RICHTIG)
TABLES=("ecokart-products")
```

**Was ich gelernt habe:**
- Naming Conventions dokumentieren!
- Hardcoded Werte vermeiden
- Bei Cleanup: Immer testen ob Ressourcen wirklich gefunden werden
- Logging ist wichtig ("Table XY wird gelÃ¶scht...")

---

### Challenge #3: DynamoDB Table Deletion mit Wait-Logic

**Das Problem:**
```bash
aws dynamodb delete-table --table-name ecokart-products
# Script geht weiter... aber Table existiert noch!
```

**Die LÃ¶sung:**
```bash
aws dynamodb delete-table --table-name ecokart-products

# WICHTIG: Warten bis wirklich gelÃ¶scht!
aws dynamodb wait table-not-exists --table-name ecokart-products
```

**Was ich gelernt habe:**
- AWS Operations sind asynchron
- `delete-table` startet nur die LÃ¶schung
- `wait` ist KRITISCH fÃ¼r zuverlÃ¤ssige Scripts
- Ohne Wait: Race Conditions!

---

## ğŸ“ Skills die ich entwickelt habe

### Technical Skills

âœ… **Infrastructure as Code**
- Terraform Module schreiben
- Terraform State Management verstehen
- Environment-spezifische Configs

âœ… **CI/CD Pipelines**
- GitHub Actions Workflows schreiben
- OIDC Authentifizierung konfigurieren
- Branch-basierte Deployment-Logik

âœ… **AWS Services**
- Lambda (Serverless Functions)
- DynamoDB (NoSQL Database)
- API Gateway (REST APIs)
- Amplify (Frontend Hosting)
- IAM (Permissions & Roles)
- CloudWatch (Logging & Monitoring)

âœ… **Git & Version Control**
- Branching-Strategien
- Pull Request Workflow
- Merge-Konflikte lÃ¶sen

âœ… **Debugging & Problem-Solving**
- Logs analysieren (CloudWatch, GitHub Actions)
- AWS Console fÃ¼r Manual Checks
- Systematisches Troubleshooting

---

### Soft Skills

âœ… **Strukturiertes Arbeiten**
- Todo-Listen fÃ¼hren
- Schritt-fÃ¼r-Schritt Approach
- Dokumentation wÃ¤hrend Development

âœ… **Kostenbe

wusstsein**
- Cloud-Kosten verstehen
- Optimization-Strategien
- Budget-Management (15$/Monat Sandbox!)

âœ… **Best Practices anwenden**
- Security (keine Secrets in Code)
- Testing (erst dev â†’ staging â†’ prod)
- Documentation (fÃ¼r mein zukÃ¼nftiges Ich)

---

## ğŸ“Š Vorher vs. Nachher

### Vorher (Tutorial-Level)
```
âŒ Ein Branch (main)
âŒ Manuelle Deployments
âŒ Keine CI/CD
âŒ Testen in Production
âŒ Keine Environment-Trennung
âŒ AWS Keys in GitHub Secrets
âŒ Keine Dokumentation
```

### Nachher (Professional-Level)
```
âœ… Drei Branches (develop/staging/main)
âœ… Automatische Deployments via GitHub Actions
âœ… VollstÃ¤ndige CI/CD Pipeline
âœ… Sichere Test-Umgebungen
âœ… Multi-Environment Setup
âœ… OIDC (keine Keys!)
âœ… Umfangreiche Dokumentation
```

---

## ğŸš€ NÃ¤chste Schritte (Roadmap)

### Kurzfristig
- [ ] Inventory Management (Stock-Tracking)
- [ ] AWS Cognito (echte User-Auth)
- [ ] Deployment Notifications (Slack/Discord)

### Mittelfristig
- [ ] Stripe Payment Integration
- [ ] Email Notifications (SES)
- [ ] Product Image Upload (S3)
- [ ] CloudWatch Alarms & Dashboards

### Langfristig
- [ ] Blue/Green Deployments
- [ ] Automated Testing (Unit, Integration, E2E)
- [ ] Performance Monitoring
- [ ] Remote Terraform State (S3)

---

## ğŸ’¼ Portfolio-Relevanz

### Was ich in Bewerbungen schreiben kann:

> **Ecokart - Serverless E-Commerce Platform**
>
> Entwicklung einer vollstÃ¤ndigen E-Commerce-Plattform auf AWS mit professionellem Multi-Environment Setup.
>
> **Tech Stack:**
> - **Backend:** Node.js/Express.js auf AWS Lambda
> - **Frontend:** Next.js 15 auf AWS Amplify
> - **Database:** AWS DynamoDB
> - **Infrastructure:** Terraform (100% IaC)
> - **CI/CD:** GitHub Actions mit OIDC
>
> **Highlights:**
> - Multi-Environment Setup (Development, Staging, Production)
> - Kostenoptimierung durch environment-spezifische Ressourcen-Sizing (60% Saving)
> - Vollautomatische CI/CD Pipeline mit Branch-basierter Deployment-Logik
> - Implementierung von AWS Best Practices (OIDC, IAM Least Privilege)
>
> **Learnings:**
> - Infrastructure as Code (Terraform)
> - AWS Serverless Architecture
> - Git Branching-Strategien
> - Debugging komplexer Deployment-Probleme

---

## ğŸ¯ Key Takeaways

1. **Multi-Environment ist NICHT optional** - Es ist Standard in Professional Development

2. **Automation spart Zeit UND reduziert Fehler** - Einmalig Setup investieren lohnt sich

3. **Documentation ist fÃ¼r mein zukÃ¼nftiges Ich** - In 3 Monaten habe ich alles vergessen!

4. **Testing in Production ist KEINE Option** - Immer develop â†’ staging â†’ main

5. **AWS Console kennen ist wichtig** - Nicht blind Automation vertrauen

6. **Cost Optimization beginnt beim Design** - Nicht erst nachtrÃ¤glich

7. **Best Practices existieren aus einem Grund** - Nicht reinventing the wheel

---

## ğŸ™ Danke

Dieses Projekt hat mir gezeigt, dass **professionelles Software-Engineering** mehr ist als nur "Code schreiben". Es geht um:

- Strukturiertes Arbeiten
- Best Practices anwenden
- Probleme systematisch lÃ¶sen
- Dokumentieren fÃ¼r andere (und mein zukÃ¼nftiges Ich)
- Kosteneffizient denken

**Von Tutorial zu Production-Ready - Mission accomplished!** ğŸ‰

---

**Erstellt:** 19. November 2025
**Autor:** Andy Schlegel
**Projekt:** Ecokart E-Commerce Platform
**Status:** Living Document (wird kontinuierlich erweitert)
